{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9ab8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6020d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serious dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_classes=3, n_samples=1000, n_features=6, n_informative=4, n_redundant=2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a5398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard dataset\n",
    "\n",
    "X, y = make_classification(n_classes=3, n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a47f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9476fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c1fcedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 0 : 87.39 % of  0.0 class elements, as per seed\n",
      "set 1 : 69.75 % of  0.0 class elements, as per seed\n",
      "set 2 : 89.08 % of  0.0 class elements, as per seed\n",
      "set 3 : 52.1 % of  2.0 class elements, as per seed\n",
      "set 4 : 55.46 % of  0.0 class elements, as per seed\n",
      "set 5 : 84.03 % of  1.0 class elements, as per seed\n",
      "set 6 : 63.87 % of  0.0 class elements, as per seed\n",
      "set 7 : 92.44 % of  2.0 class elements, as per seed\n",
      "set 8 : 57.98 % of  0.0 class elements, as per seed\n",
      "set 9 : 68.91 % of  1.0 class elements, as per seed\n",
      "set 10 : 63.87 % of  2.0 class elements, as per seed\n",
      "set 11 : 74.79 % of  2.0 class elements, as per seed\n",
      "set 12 : 73.11 % of  0.0 class elements, as per seed\n",
      "set 13 : 85.71 % of  0.0 class elements, as per seed\n",
      "set 14 : 80.67 % of  0.0 class elements, as per seed\n",
      "set 15 : 59.66 % of  0.0 class elements, as per seed\n",
      "set 16 : 84.03 % of  0.0 class elements, as per seed\n",
      "set 17 : 55.46 % of  1.0 class elements, as per seed\n",
      "set 18 : 49.58 % of  0.0 class elements, as per seed\n",
      "set 19 : 45.38 % of  0.0 class elements, as per seed\n",
      "set 20 : 83.19 % of  2.0 class elements, as per seed\n",
      "set 21 : 57.98 % of  1.0 class elements, as per seed\n",
      "set 22 : 47.9 % of  0.0 class elements, as per seed\n",
      "set 23 : 63.87 % of  2.0 class elements, as per seed\n",
      "set 24 : 43.7 % of  1.0 class elements, as per seed\n",
      "set 25 : 70.59 % of  2.0 class elements, as per seed\n",
      "set 26 : 46.22 % of  1.0 class elements, as per seed\n",
      "set 27 : 64.71 % of  1.0 class elements, as per seed\n",
      "set 28 : 47.06 % of  0.0 class elements, as per seed\n",
      "set 29 : 70.59 % of  1.0 class elements, as per seed\n",
      "set 30 : 47.9 % of  0.0 class elements, as per seed\n",
      "set 31 : 74.79 % of  2.0 class elements, as per seed\n",
      "set 32 : 41.18 % of  2.0 class elements, as per seed\n",
      "set 33 : 63.87 % of  1.0 class elements, as per seed\n",
      "set 34 : 59.66 % of  1.0 class elements, as per seed\n",
      "set 35 : 55.46 % of  2.0 class elements, as per seed\n",
      "set 36 : 57.14 % of  2.0 class elements, as per seed\n",
      "set 37 : 44.54 % of  0.0 class elements, as per seed\n",
      "set 38 : 48.74 % of  1.0 class elements, as per seed\n",
      "set 39 : 47.9 % of  0.0 class elements, as per seed\n",
      "set 40 : 52.1 % of  1.0 class elements, as per seed\n",
      "set 41 : 58.82 % of  2.0 class elements, as per seed\n",
      "set 42 : 36.13 % of  2.0 class elements, as per seed\n",
      "set 43 : 40.34 % of  0.0 class elements, as per seed\n",
      "set 44 : 44.54 % of  0.0 class elements, as per seed\n",
      "set 45 : 36.13 % of  2.0 class elements, as per seed\n",
      "set 46 : 33.61 % of  0.0 class elements, as per seed\n",
      "set 47 : 29.41 % of  0.0 class elements, as per seed\n",
      "set 48 : 31.09 % of  1.0 class elements, as per seed\n",
      "set 49 : 25.21 % of  0.0 class elements, as per seed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "def _custom_bootstrap(X, y, similarity_function, n_estimators):\n",
    "    \n",
    "    #Initializing list of random training sets\n",
    "    X_sets = []\n",
    "    y_sets = []\n",
    "    \n",
    "    for i in range(0,n_estimators):\n",
    "        instance_X = np.empty(np.shape(X))\n",
    "        instance_y = np.empty(np.shape(y))\n",
    "        \n",
    "        #creating seed for specific training set\n",
    "        seed = randint(0,len(X)-1)\n",
    "        \n",
    "        instance_X[0] = X[seed]\n",
    "        instance_y[0] = y[seed]       \n",
    "        \n",
    "        n_entries = 1\n",
    "        \n",
    "        #populating training set\n",
    "        \n",
    "        \n",
    "        if 1-(len(X_sets)+1)/n_estimators>0.8:\n",
    "            p_thresh = 0.8\n",
    "        else:\n",
    "            p_thresh = np.round(1-(len(X_sets)+1)/n_estimators,1)\n",
    "        \n",
    "        #print(\"populating set\", i, \"with probability acceptance\",p_thresh)\n",
    "        \n",
    "        \n",
    "        while n_entries < len(X):\n",
    "            \n",
    "            rand = randint(0,len(X)-1)\n",
    "            \n",
    "            if _accept_entry(similarity_function[seed,rand],n_entries/(len(X)-1),p_thresh):\n",
    "                \n",
    "                instance_X[n_entries] = X[rand]\n",
    "                instance_y[n_entries] = y[rand]\n",
    "                n_entries+=1\n",
    "                \n",
    "        X_sets.append(instance_X)\n",
    "        y_sets.append(instance_y)     \n",
    "    \n",
    "    return X_sets,y_sets\n",
    "\n",
    "def _accept_entry(similarity_score, p_ratio, prob_threshold = 0.7):\n",
    "    #p_ratio gradually shifts the decisional weight from similarity_score to randomness as the test set gets filled up.\n",
    "    #Specifically, at least least a small number of entries are accepted only through randomness (p_ratio=1)\n",
    "    #this way it's unlikely for the method to come up with sets with only one class (if not impossible, but I need to check)\n",
    "    \n",
    "    #It is also possible to modify the prob_threshold in order to get more or less random values, assuring more variance.\n",
    "    #I think this tweakability could prove useful to adapt the model to specific instances.\n",
    "    \n",
    "    #PLEASE NOTE THAT THIS CODE MAKES SENSE WITH NORMALIZED SIMILARITY SCORES\n",
    "    #NORMALIZATION FOR FUNCTION THAT DO NOT RETURN [0,1] VALUES STILL NEEDS TO BE IMPLEMENTED.\n",
    "    #It's not like it doesn't work, but prob calculations take the high road\n",
    "    \n",
    "    prob = similarity_score*(1-p_ratio)+ random.random()*p_ratio\n",
    "    if prob > prob_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def _normalize(X):\n",
    "    #todo, in case the class needs to accept non-normalized similarity functions\n",
    "    return X\n",
    "\n",
    "\n",
    "#Test\n",
    "X_sets, y_sets = _custom_bootstrap(X_train, y_train,pairwise_kernels(X_train, metric='rbf'),50)\n",
    "\n",
    "for i in range(len(X_sets)):\n",
    "    for j in range (0,len(X_sets[0][:,0])):\n",
    "        if j==0:\n",
    "            s = y_sets[i][j]\n",
    "            g=0\n",
    "        else:\n",
    "            if y_sets[i][j] == s:\n",
    "                g+=1\n",
    "    #used to measure the effects of p_thresh\n",
    "    print (\"set\",i,\":\",np.round(g/j*100,2),\"% of \",y_sets[i][j],\"class elements, as per seed\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c060de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEstimator(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_estimators,\n",
    "                base_estimator=DecisionTreeClassifier(),\n",
    "                similarity_function=pairwise_kernels(X, metric='rbf'),\n",
    "                verbose = 0):\n",
    "        \n",
    "        self.n_estimators = n_estimators \n",
    "        self.base_estimator = base_estimator\n",
    "        self.similarity_function = similarity_function\n",
    "        self.verbose=verbose #0 = None; 1 = Messages to confirm that the estimator is alive while working; 2 = spits out data \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        self.n_classes_= np.max(y)+1\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Bootstrapping...\")\n",
    "        self.X_sets, self.y_sets = _custom_bootstrap(X, y, self.similarity_function, self.n_estimators)\n",
    "        #dummy_value = self.base_estimator.fit(X,y)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Fitting...\")\n",
    "        \n",
    "        for i in range(self.n_estimators):        \n",
    "            model = self.base_estimator.fit(self.X_sets[i], self.y_sets[i])\n",
    "            model_name = \"model\"+str(i)+\".pkl\"\n",
    "            joblib.dump(model, model_name)\n",
    "            \n",
    "            \n",
    "        #self.value_ = dummy_value\n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        if self.verbose > 0:\n",
    "            print(\"Done!\")\n",
    "        #return self #For some reason this produces an error\n",
    "                \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predicted_probabilitiy = self.predict_proba(X)\n",
    "        return np.argmax(predicted_probabilitiy, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "            \n",
    "        if self.verbose > 0:\n",
    "            print(\"Predicting...\")\n",
    "            \n",
    "        out = np.zeros(shape=(len(X),self.n_classes_))\n",
    "        \n",
    "        #compute similarity between instance and each training set\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Computing models similarity to instance...\")\n",
    "        \n",
    "        Z=[]\n",
    "        for j in range (0,self.n_estimators):\n",
    "            Z.append(pairwise_kernels(X, self.X_sets[j], metric='rbf'))\n",
    "        \n",
    "        if self.verbose > 1:\n",
    "            print(Z)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Making predictions with each trained model...\")\n",
    "            \n",
    "          \n",
    "        for i in range(0,len(X)): #for each sample to predict\n",
    "            if self.verbose > 1:  \n",
    "                print(\"evaluating sample\",i)\n",
    "            \n",
    "            votes = []\n",
    "            sim_means = np.zeros(self.n_estimators)\n",
    "            \n",
    "            voting_power = np.zeros(self.n_estimators)\n",
    "            \n",
    "            for j in range (0,self.n_estimators): #for each estimator trained\n",
    "               \n",
    "                #load estimator model\n",
    "                model_name = \"model\"+str(j)+\".pkl\"\n",
    "                model = joblib.load(model_name)\n",
    "                \n",
    "                votes.append(model.predict_proba(X[i].reshape(1, -1))) \n",
    "                sim_means[j] = np.mean(Z[j][i]) #not sure about using the mean\n",
    "            \n",
    "                if self.verbose > 1:\n",
    "                    print(\"votes:\",np.round(votes[j],2),\"similarity:\",np.round(sim_means[j],2))\n",
    "                    print(sim_means)\n",
    "           \n",
    "                voting_power[j] = (100*sim_means[j]/np.sum(sim_means))/100\n",
    "                votes[j]=votes[j]*voting_power[j]\n",
    "        \n",
    "            if self.verbose > 1:\n",
    "                print(\"voting power:\",voting_power)\n",
    "                \n",
    "            out[i]=(np.sum(votes,axis=0))\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Done!\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2544b9e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping...\n",
      "Fitting...\n",
      "Done!\n",
      "Predicting...\n",
      "Computing models similarity to instance...\n",
      "Making predictions with each trained model...\n",
      "Done!\n",
      "Accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test instance \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "clf = CustomEstimator(n_estimators=50,\n",
    "                             base_estimator=DecisionTreeClassifier(),\n",
    "                             similarity_function=pairwise_kernels(X, metric='rbf'),verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy =\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be773b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Comparative tests\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=50, max_leaf_nodes=16, n_jobs=-1)\n",
    "\n",
    "svc_clf = SVC(probability=True)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=16)\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "\n",
    "custom_clf = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier(),verbose=True)\n",
    "\n",
    "print(\"Accuracy scores:\")\n",
    "for clf in (rnd_clf, svc_clf, tree_clf, bag_clf, custom_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,\":\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "#     results, names = list(), list()\n",
    "#     scores = evaluate_model(clf, X, y)\n",
    "#     results.append(scores)\n",
    "#     names.append(clf.__class__.__name__)\n",
    "#     print('%s %.3f (%.3f)' % (\"Cross validation score:\", np.mean(scores), np.std(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import check_pairwise_arrays\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "pairwise_kernels(X, Y=None, metric=\"laplacian\")\n",
    "\n",
    "#[‘additive_chi2’, ‘chi2’, ‘linear’, ‘poly’, ‘polynomial’, ‘rbf’, ‘laplacian’, ‘sigmoid’, ‘cosine’]\n",
    "\n",
    "#normalized metrics: rbf, laplacian, cosine\n",
    "#cosine doesn't make much sense i guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
