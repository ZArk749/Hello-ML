{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9ab8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a5398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard dataset\n",
    "\n",
    "X, y = make_classification(n_classes=3, n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a47f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toy dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6020d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serious dataset\n",
    "\n",
    "X, y = make_classification(n_classes=3, n_samples=1000, n_features=6, n_informative=4, n_redundant=2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9476fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1168304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95. 146.  57.  97. 145. 112. 137. 147. 144.  15.]\n",
      "57.0\n",
      "[140. 112. 144. 144.  66. 103. 112.  63. 137. 132.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "def _rejection_bootstrap(X, y, similarity_metric, n_estimators):\n",
    "    \n",
    "    #Initializing list of random training sets\n",
    "    X_sets = []\n",
    "    y_sets = []\n",
    "    G = pairwise_kernels(X, metric=similarity_metric)\n",
    "    \n",
    "    seed=None\n",
    "    \n",
    "    for i in range(0,n_estimators):\n",
    "        \n",
    "        instance_X = np.empty(np.shape(X))\n",
    "        instance_y = np.empty(np.shape(y))\n",
    "\n",
    "        seed = _pickDiverseSeed(G,seed)\n",
    "        \n",
    "        instance_X[0] = X[seed]\n",
    "        instance_y[0] = y[seed]       \n",
    "        \n",
    "        n_entries = 1\n",
    "        \n",
    "        #populating training set\n",
    "        \n",
    "        \n",
    "        if 1-(len(X_sets)+1)/n_estimators>0.8:\n",
    "            p_thresh = 0.8\n",
    "        else:\n",
    "            p_thresh = np.round(1-(len(X_sets)+1)/n_estimators,1)\n",
    "        \n",
    "        #print(\"populating set\", i, \"with probability acceptance\",p_thresh)\n",
    "        \n",
    "        \n",
    "        while n_entries < len(X):\n",
    "            \n",
    "            rand = randint(0,len(X)-1)\n",
    "            \n",
    "            if _accept_entry(G[seed,rand],n_entries/(len(X)-1),p_thresh):\n",
    "                \n",
    "                instance_X[n_entries] = X[rand]\n",
    "                instance_y[n_entries] = y[rand]\n",
    "                n_entries+=1\n",
    "                \n",
    "        X_sets.append(instance_X)\n",
    "        y_sets.append(instance_y)     \n",
    "    \n",
    "    return X_sets,y_sets\n",
    "\n",
    "def _accept_entry(similarity_score, p_ratio, prob_threshold = 0.7):\n",
    "    #p_ratio gradually shifts the decisional weight from similarity_score to randomness as the test set gets filled up.\n",
    "    #Specifically, at least least a small number of entries are accepted only through randomness (p_ratio=1)\n",
    "    #this way it's unlikely for the method to come up with sets with only one class (if not impossible, but I need to check)\n",
    "    \n",
    "    #It is also possible to modify the prob_threshold in order to get more or less random values, assuring more variance.\n",
    "    #I think this tweakability could prove useful to adapt the model to specific instances.\n",
    "    \n",
    "    #PLEASE NOTE THAT THIS CODE MAKES SENSE WITH NORMALIZED SIMILARITY SCORES\n",
    "    #NORMALIZATION FOR FUNCTION THAT DO NOT RETURN [0,1] VALUES STILL NEEDS TO BE IMPLEMENTED.\n",
    "    #It's not like it doesn't work, but prob calculations take the high road\n",
    "    \n",
    "    prob = similarity_score*(1-p_ratio)+ random.random()*p_ratio\n",
    "    if prob > prob_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def _validate(metric, bootstrap_method):\n",
    "    \n",
    "    if bootstrap_method is not None:\n",
    "        if bootstrap_method not in (\"rejection\",\"randomchoice\"):\n",
    "            raise ValueError(\n",
    "                'Invalid preset \"%s\" for bootstrap_method'\n",
    "                % bootstrap_method\n",
    "                )\n",
    "    \n",
    "    if metric is not None:\n",
    "        if metric not in (\"rbf\", \"laplacian\",\"cosine\"):\n",
    "            raise ValueError(\n",
    "                'Invalid preset \"%s\" for kernel metric'\n",
    "                % metric\n",
    "                )\n",
    "            \n",
    "def _pickDiverseSeed(sim_matrix,seed=None):\n",
    "    #creating seed for specific training set, choosing by inverse similarity to previous set\n",
    "    if seed is None:\n",
    "            return randint(0,len(sim_matrix)-1)\n",
    "    else:\n",
    "        #questo è probabilmente il codice più cringe che io abbia mai scritto,\n",
    "        #ma non riesco a fargli ritornare un int se non specificando l'indice\n",
    "\n",
    "        sim_n = 1-sim_matrix[seed]\n",
    "\n",
    "        candidate = np.random.choice(np.arange(len(sim_matrix)), size=1, replace=True,\n",
    "                                     p=sim_n/np.sum(sim_n))[0]\n",
    "\n",
    "        return candidate\n",
    "    \n",
    "def _pickDiverseSeed2(sim_matrix,seed):\n",
    "    #creating seed for specific training set, choosing by inverse similarity to previous set\n",
    "    l=len(seed)\n",
    "    if len(seed) == 0:\n",
    "        return randint(0,len(sim_matrix)-1)\n",
    "    else:\n",
    "        \n",
    "        candidates = np.zeros(l)\n",
    "        \n",
    "        for i in range(0,len(seed)):\n",
    "\n",
    "            sim_n = 1-sim_matrix[seed[i]]\n",
    "\n",
    "            candidates[i] = np.random.choice(np.arange(len(sim_matrix)), size=1, replace=True, \n",
    "                                             p=sim_n/np.sum(sim_n))[0]\n",
    "        print(candidates)\n",
    "        \n",
    "\n",
    "        return np.random.choice(candidates, size=1, replace=True)[0]\n",
    "    \n",
    "test = [1,4,8,6,52,3,4,98,2,6]\n",
    "h = pairwise_kernels(iris.data, metric=\"laplacian\")\n",
    "\n",
    "h1 = _pickDiverseSeed2(h,test)\n",
    "print(h1)\n",
    "test.append(_pickDiverseSeed2(h,test))\n",
    "    \n",
    "\n",
    "\n",
    "#Test\n",
    "X_sets, y_sets = _rejection_bootstrap(X_train, y_train,'rbf',50)\n",
    "\n",
    "# for i in range(len(X_sets)):\n",
    "#     for j in range (0,len(X_sets[0][:,0])):\n",
    "#         if j==0:\n",
    "#             s = y_sets[i][j]\n",
    "#             g=0\n",
    "#         else:\n",
    "#             if y_sets[i][j] == s:\n",
    "#                 g+=1\n",
    "#     #used to measure the effects of p_thresh\n",
    "#     print (\"set\",i,\":\",np.round(g/j*100,2),\"% of \",y_sets[i][j],\"class elements, as per seed\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a11a356e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n",
      "42.949250596224275\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m         y_sets\u001b[38;5;241m.\u001b[39mappend(instance_y)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_sets,y_sets\n\u001b[1;32m---> 67\u001b[0m X_sets,y_sets \u001b[38;5;241m=\u001b[39m \u001b[43m_randomchoice_bootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrbf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m_randomchoice_bootstrap\u001b[1;34m(X, y, similarity_metric, n_estimators, verbose)\u001b[0m\n\u001b[0;32m     35\u001b[0m             pool_prob[i] \u001b[38;5;241m=\u001b[39m G[seed[i]][j]\u001b[38;5;241m/\u001b[39mpool_tot\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#         if False:  #adds noise, does not increase accuracy\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#             for i in range(0,int(np.shape(X)[0]/2)):\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#                 offset = 0.3 #random.uniform(0, 1)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#         print(G[seed])\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m         pick \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pick)):\n\u001b[0;32m     59\u001b[0m             instance_X[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m X[pool[i]]\n",
      "File \u001b[1;32mmtrand.pyx:939\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: probabilities do not sum to 1"
     ]
    }
   ],
   "source": [
    "def _randomchoice_bootstrap(X, y, similarity_metric, n_estimators, verbose=0):\n",
    "    #Initializing list of random training sets\n",
    "    X_sets = []\n",
    "    y_sets = []\n",
    "    G = pairwise_kernels(X, metric=similarity_metric)\n",
    "    \n",
    "    seed=None\n",
    "    \n",
    "    for i in range(0,n_estimators):\n",
    "        instance_X = np.empty(np.shape(X))\n",
    "        instance_y = np.empty(np.shape(y))\n",
    "        \n",
    "        #creating seed for specific training set\n",
    "        \n",
    "        if verbose>0:\n",
    "            oldseed=seed\n",
    "        \n",
    "        seed = _pickDiverseSeed(G,seed)\n",
    "        \n",
    "        if verbose>0 and oldseed is not None:\n",
    "            print(\"Chose new seed\",seed,\"based on previous one:\",oldseed,\"w/ similarity:\",G[seed][oldseed])\n",
    "                  \n",
    "\n",
    "        instance_X[0] = X[seed]\n",
    "        instance_y[0] = y[seed]\n",
    "        \n",
    "        pool = np.arange(np.shape(X)[0])\n",
    "        pool_prob = np.zeros(np.shape(X)[0])\n",
    "        pool_tot = np.sum(G[seed])\n",
    "        \n",
    "        \n",
    "        for i in range(np.shape(X)[0]):\n",
    "            pool_prob[i] = G[seed][i]/pool_tot\n",
    "        \n",
    "        if False:  #adds noise, does not increase accuracy\n",
    "            for i in range(0,int(np.shape(X)[0]/2)):\n",
    "                offset = 0.3 #random.uniform(0, 1)\n",
    "                \n",
    "                index = randint(0,np.shape(X)[0]-1)\n",
    "                while pool_prob[index] + offset > 1: \n",
    "                    index = randint(0,np.shape(X)[0]-1)\n",
    "                pool_prob[index] += offset\n",
    "                \n",
    "                index = randint(0,np.shape(X)[0])-1\n",
    "                while pool_prob[index] - offset < 0: \n",
    "                    index = randint(0,np.shape(X)[0]-1)\n",
    "                pool_prob[index] -= offset\n",
    "                \n",
    "                \n",
    "#         print(pool_prob)\n",
    "        \n",
    "#         print(G[seed])\n",
    "        \n",
    "        pick = np.random.choice(pool, size=(len(pool))-1, replace=True, p=pool_prob)\n",
    "        \n",
    "        for i in range(len(pick)):\n",
    "            instance_X[i+1] = X[pool[i]]\n",
    "            instance_y[i+1] = y[pool[i]]\n",
    "        \n",
    "        X_sets.append(instance_X)\n",
    "        y_sets.append(instance_y)\n",
    "    \n",
    "    return X_sets,y_sets\n",
    "\n",
    "X_sets,y_sets = _randomchoice_bootstrap(X_train,y_train,\"rbf\",n_estimators=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c060de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : int, default=50\n",
    "        The number of models to train.\n",
    "        \n",
    "    base_estimator : estimator, default=DecisionTreeClassifier()\n",
    "        The estimator fitted on  each bootstrapped set.\n",
    "        \n",
    "    similarity_metric : {\"rbf\", \"laplacian\", \"cosine\"}, string, default=\"rbf\"\n",
    "        The metric used for pairwise_kernels().\n",
    "        \n",
    "    bootstrap_method={\"rejection\", \"randomchoice\"}, string, default=TODO\n",
    "        The bootstrap method of choice.\n",
    "    \n",
    "    verbose : int, default = 0\n",
    "        Controls verbosity during fitting and predicting, 0 being none and 2 being the most verbose. \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class CustomEstimator(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_estimators=50,\n",
    "                base_estimator=DecisionTreeClassifier(),\n",
    "                bootstrap_method=\"rejection\",\n",
    "                similarity_metric=\"rbf\",\n",
    "                verbose = 0):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.n_estimators = n_estimators \n",
    "        self.base_estimator = base_estimator\n",
    "        self.bootstrap_method = bootstrap_method\n",
    "        self.similarity_metric = similarity_metric\n",
    "        self.verbose = verbose \n",
    "        \n",
    "        _validate(self.similarity_metric, self.bootstrap_method)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        self.n_classes_= np.max(y)+1\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Bootstrapping...\")\n",
    "            \n",
    "        if self.bootstrap_method==\"rejection\":  \n",
    "            self.X_sets, self.y_sets = _rejection_bootstrap(X, y, self.similarity_metric, self.n_estimators)\n",
    "        elif self.bootstrap_method==\"randomchoice\": \n",
    "            self.X_sets, self.y_sets = _randomchoice_bootstrap(X, y, self.similarity_metric, self.n_estimators)\n",
    "        \n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Fitting...\")\n",
    "        \n",
    "        for i in range(self.n_estimators):        \n",
    "            model = self.base_estimator.fit(self.X_sets[i], self.y_sets[i])\n",
    "            model_name = \"model\"+str(i)+\".pkl\"\n",
    "            joblib.dump(model, model_name)\n",
    "            \n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "\n",
    "        if self.verbose > 0:\n",
    "            print(\"Done!\")\n",
    "        #return self #For some reason this produces an error\n",
    "                \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predicted_probabilitiy = self.predict_proba(X)\n",
    "        return np.argmax(predicted_probabilitiy, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "            \n",
    "        if self.verbose > 0:\n",
    "            print(\"Predicting...\")\n",
    "            \n",
    "        out = np.zeros(shape=(len(X),self.n_classes_))\n",
    "        \n",
    "        #compute similarity between instance and each training set\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Computing models similarity to instance...\")\n",
    "        \n",
    "        Z=[]\n",
    "        for j in range (0,self.n_estimators):\n",
    "            Z.append(pairwise_kernels(X, self.X_sets[j], metric=self.similarity_metric))\n",
    "        \n",
    "        if self.verbose > 1:\n",
    "            print(Z)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Making predictions with each trained model...\")\n",
    "            \n",
    "          \n",
    "        for i in range(0,len(X)): #for each sample to predict\n",
    "            if self.verbose > 1:  \n",
    "                print(\"evaluating sample\",i)\n",
    "            \n",
    "            votes = []\n",
    "            sim_means = np.zeros(self.n_estimators)\n",
    "            \n",
    "            voting_power = np.zeros(self.n_estimators)\n",
    "            \n",
    "            for j in range (0,self.n_estimators): #for each estimator trained\n",
    "               \n",
    "                #load estimator model\n",
    "                model_name = \"model\"+str(j)+\".pkl\"\n",
    "                model = joblib.load(model_name)\n",
    "                \n",
    "                votes.append(model.predict_proba(X[i].reshape(1, -1))) \n",
    "                sim_means[j] = np.mean(Z[j][i]) \n",
    "            \n",
    "                if self.verbose > 1:\n",
    "                    print(\"votes:\",np.round(votes[j],2),\"similarity:\",np.round(sim_means[j],2))\n",
    "                    print(sim_means)\n",
    "           \n",
    "                voting_power[j] = (100*sim_means[j]/np.sum(sim_means))/100\n",
    "                votes[j]=votes[j]*voting_power[j]\n",
    "        \n",
    "            if self.verbose > 1:\n",
    "                print(\"voting power:\",voting_power)\n",
    "                \n",
    "            out[i]=(np.sum(votes,axis=0))\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(\"Done!\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e92a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping...\n",
      "Fitting...\n",
      "Done!\n",
      "Predicting...\n",
      "Computing models similarity to instance...\n",
      "Making predictions with each trained model...\n",
      "Done!\n",
      "rbf/rej : 0.815\n",
      "rbf/raC : 0.79\n",
      "Lap/rej : 0.835\n",
      "Lap/raC : 0.785\n"
     ]
    }
   ],
   "source": [
    "#Accuracy comparison w/different parameters\n",
    "\n",
    "clf1 = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier(), verbose=1)\n",
    "clf2 = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier(),bootstrap_method=\"randomchoice\")\n",
    "clf3 = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier(),similarity_metric=\"laplacian\")\n",
    "clf4 = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier(),similarity_metric=\"laplacian\",bootstrap_method=\"randomchoice\")\n",
    "\n",
    "A = [(\"rbf/rej\",clf1),(\"rbf/raC\",clf2),(\"Lap/rej\",clf3),(\"Lap/raC\",clf4)]\n",
    "\n",
    "for i in range(0,len(A)):\n",
    "    A[i][1].fit(X_train, y_train)\n",
    "    y_pred = A[i][1].predict(X_test)\n",
    "    print(A[i][0],\":\",metrics.accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74215001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping...\n",
      "Fitting...\n",
      "Done!\n",
      "Predicting...\n",
      "Computing models similarity to instance...\n",
      "Making predictions with each trained model...\n",
      "Done!\n",
      "Accuracy = 0.76\n"
     ]
    }
   ],
   "source": [
    "# Test instance \n",
    "\n",
    "clf = CustomEstimator(n_estimators=50,\n",
    "                             base_estimator=DecisionTreeClassifier(),bootstrap_method=\"randomchoice\",\n",
    "                             similarity_metric='rbf',verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy =\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86be773b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores:\n",
      "RandomForestClassifier : 0.795\n",
      "SVC : 0.865\n",
      "DecisionTreeClassifier : 0.78\n",
      "BaggingClassifier : 0.79\n",
      "CustomEstimator : 0.81\n",
      "CustomEstimator : 0.79\n",
      "CustomEstimator : 0.765\n"
     ]
    }
   ],
   "source": [
    "# Comparative tests\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=50, max_leaf_nodes=16, n_jobs=-1)\n",
    "\n",
    "svc_clf = SVC(probability=True)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=16)\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=50, max_samples=100, bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "\n",
    "custom_clf = CustomEstimator(n_estimators=50,base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "custom_clf2 = CustomEstimator(n_estimators=50,similarity_metric=\"laplacian\")\n",
    "\n",
    "custom_clf3 = CustomEstimator(n_estimators=50,similarity_metric=\"laplacian\", bootstrap_method=\"randomchoice\")\n",
    "\n",
    "print(\"Accuracy scores:\")\n",
    "for clf in (rnd_clf, svc_clf, tree_clf, bag_clf, custom_clf, custom_clf2, custom_clf3):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,\":\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "#     results, names = list(), list()\n",
    "#     scores = evaluate_model(clf, X, y)\n",
    "#     results.append(scores)\n",
    "#     names.append(clf.__class__.__name__)\n",
    "#     print('%s %.3f (%.3f)' % (\"Cross validation score:\", np.mean(scores), np.std(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7692dd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.36713288, -0.49438263, ...,  0.93817176,\n",
       "         0.26485983,  0.72455268],\n",
       "       [ 0.36713288,  1.        , -0.70683046, ...,  0.46766292,\n",
       "         0.65104316, -0.10009633],\n",
       "       [-0.49438263, -0.70683046,  1.        , ..., -0.35923055,\n",
       "        -0.43796732,  0.0947128 ],\n",
       "       ...,\n",
       "       [ 0.93817176,  0.46766292, -0.35923055, ...,  1.        ,\n",
       "         0.211382  ,  0.79763951],\n",
       "       [ 0.26485983,  0.65104316, -0.43796732, ...,  0.211382  ,\n",
       "         1.        , -0.36418777],\n",
       "       [ 0.72455268, -0.10009633,  0.0947128 , ...,  0.79763951,\n",
       "        -0.36418777,  1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import check_pairwise_arrays\n",
    "\n",
    "pairwise_kernels(X, Y=None, metric=\"cosine\")\n",
    "\n",
    "#[‘additive_chi2’, ‘chi2’, ‘linear’, ‘poly’, ‘polynomial’, ‘rbf’, ‘laplacian’, ‘sigmoid’, ‘cosine’]\n",
    "\n",
    "#normalized metrics: rbf, laplacian\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d1b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.4602264424791063, 1.4602264424791063, 1.4602264424791063]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "a = np.random.rand(3,2)\n",
    "\n",
    "%time np.sum(a[0],axis=0)\n",
    "\n",
    "%time [Parallel(n_jobs=2)(delayed(np.sum)(a[0],axis=0) for i in range(len(a)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
